\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Overview of object recognition and tracking}{chapter.1}% 2
\BOOKMARK [2][-]{subsection.1.1.1}{Object recognition}{section.1.1}% 3
\BOOKMARK [2][-]{subsection.1.1.2}{Object Tracking}{section.1.1}% 4
\BOOKMARK [1][-]{section.1.2}{Context and scope of the thesis}{chapter.1}% 5
\BOOKMARK [2][-]{subsection.1.2.1}{Egocentric vision}{section.1.2}% 6
\BOOKMARK [2][-]{subsection.1.2.2}{Background project}{section.1.2}% 7
\BOOKMARK [1][-]{section.1.3}{Related works}{chapter.1}% 8
\BOOKMARK [2][-]{subsection.1.3.1}{Video object recoginiton and tracking related works}{section.1.3}% 9
\BOOKMARK [2][-]{subsection.1.3.2}{Hand recognition related works}{section.1.3}% 10
\BOOKMARK [1][-]{section.1.4}{Problem formulation and assumptions}{chapter.1}% 11
\BOOKMARK [0][-]{chapter.2}{Methodology and Datasets}{}% 12
\BOOKMARK [1][-]{section.2.1}{Tracking by detection approach}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.2}{Object detection and segmentation algorithms}{chapter.2}% 14
\BOOKMARK [2][-]{subsection.2.2.1}{RCNN model family}{section.2.2}% 15
\BOOKMARK [2][-]{subsection.2.2.2}{YOLO model family}{section.2.2}% 16
\BOOKMARK [1][-]{section.2.3}{Object tracking algorithms}{chapter.2}% 17
\BOOKMARK [2][-]{subsection.2.3.1}{SORT}{section.2.3}% 18
\BOOKMARK [2][-]{subsection.2.3.2}{DeepSORT}{section.2.3}% 19
\BOOKMARK [1][-]{section.2.4}{Egocentric vision datasets}{chapter.2}% 20
\BOOKMARK [2][-]{subsection.2.4.1}{GTEA family datatsets}{section.2.4}% 21
\BOOKMARK [2][-]{subsection.2.4.2}{EgoHands dataset}{section.2.4}% 22
\BOOKMARK [2][-]{subsection.2.4.3}{Micand32 dataset}{section.2.4}% 23
\BOOKMARK [0][-]{chapter.3}{Proposed Framework}{}% 24
\BOOKMARK [1][-]{section.3.1}{Proposed framework: tracking by detection}{chapter.3}% 25
\BOOKMARK [1][-]{section.3.2}{Training stage}{chapter.3}% 26
\BOOKMARK [2][-]{subsection.3.2.1}{Training detection and segmentation models}{section.3.2}% 27
\BOOKMARK [1][-]{section.3.3}{Training Deep Appearance Descriptor for DeepSORT}{chapter.3}% 28
\BOOKMARK [1][-]{section.3.4}{Inference stage}{chapter.3}% 29
\BOOKMARK [1][-]{section.3.5}{Evaluation stage}{chapter.3}% 30
\BOOKMARK [0][-]{chapter.4}{Experiments}{}% 31
\BOOKMARK [1][-]{section.4.1}{Evaluation criteria}{chapter.4}% 32
\BOOKMARK [2][-]{subsection.4.1.1}{Object detection metrics}{section.4.1}% 33
\BOOKMARK [2][-]{subsection.4.1.2}{Object tracking metrics}{section.4.1}% 34
\BOOKMARK [1][-]{section.4.2}{Experimental results}{chapter.4}% 35
\BOOKMARK [2][-]{subsection.4.2.1}{Egocentric hand detection and segmentation result}{section.4.2}% 36
\BOOKMARK [2][-]{subsection.4.2.2}{Egocentric hand tracking result}{section.4.2}% 37
\BOOKMARK [1][-]{section.4.3}{Discussions}{chapter.4}% 38
\BOOKMARK [2][-]{subsection.4.3.1}{Object detection: tradeoff between accuracy and speed}{section.4.3}% 39
\BOOKMARK [2][-]{subsection.4.3.2}{The superiority of DeepSORT over SORT}{section.4.3}% 40
\BOOKMARK [2][-]{subsection.4.3.3}{Impact of detection method over tracking result}{section.4.3}% 41
\BOOKMARK [2][-]{subsection.4.3.4}{Complexsity of 4 type of patientsâ€™s actions}{section.4.3}% 42
\BOOKMARK [2][-]{subsection.4.3.5}{Challenging cases}{section.4.3}% 43
\BOOKMARK [0][-]{chapter.5}{Conclusion}{}% 44
\BOOKMARK [1][-]{section.5.1}{Conclusions}{chapter.5}% 45
\BOOKMARK [2][-]{subsection.5.1.1}{Accomplishment}{section.5.1}% 46
\BOOKMARK [2][-]{subsection.5.1.2}{Drawback}{section.5.1}% 47
\BOOKMARK [1][-]{section.5.2}{Future works}{chapter.5}% 48
\BOOKMARK [0][-]{appendix.A}{Tables}{}% 49
\BOOKMARK [0][-]{appendix.B}{Figures}{}% 50
