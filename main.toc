\contentsline {chapter}{\numberline {1}Introduction}{15}{chapter.1}%
\contentsline {section}{\numberline {1.1}Overview of object recognition and tracking from video}{15}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Object recognition}{15}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Object tracking}{16}{subsection.1.1.2}%
\contentsline {section}{\numberline {1.2}Context and scope of the thesis}{17}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Egocentric vision}{17}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Background project and motivation}{18}{subsection.1.2.2}%
\contentsline {section}{\numberline {1.3}Related works}{19}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Video object recognition and tracking challenges}{19}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Hand gestures recognition related works}{20}{subsection.1.3.2}%
\contentsline {section}{\numberline {1.4}Problem formulation and assumptions}{22}{section.1.4}%
\contentsline {subsection}{\numberline {1.4.1}Objective}{22}{subsection.1.4.1}%
\contentsline {subsection}{\numberline {1.4.2}Contribution}{22}{subsection.1.4.2}%
\contentsline {subsection}{\numberline {1.4.3}Thesis outline}{23}{subsection.1.4.3}%
\contentsline {chapter}{\numberline {2}Methodology and Datasets}{25}{chapter.2}%
\contentsline {section}{\numberline {2.1}Tracking by detection approach}{25}{section.2.1}%
\contentsline {section}{\numberline {2.2}Object detection and segmentation algorithms}{26}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}RCNN model}{26}{subsection.2.2.1}%
\contentsline {subsubsection}{RCNN}{26}{subsection.2.2.1}%
\contentsline {subsubsection}{FastRCNN}{28}{figure.2.1}%
\contentsline {subsubsection}{FasterRCNN}{30}{equation.2.2.13}%
\contentsline {subsubsection}{MaskRCNN}{32}{equation.2.2.16}%
\contentsline {subsection}{\numberline {2.2.2}YOLO model family}{33}{subsection.2.2.2}%
\contentsline {subsubsection}{YOLO}{33}{subsection.2.2.2}%
\contentsline {subsubsection}{YOLOv2}{34}{figure.2.5}%
\contentsline {subsubsection}{YOLOv3}{35}{figure.2.5}%
\contentsline {subsubsection}{YOLOv4}{35}{figure.2.5}%
\contentsline {section}{\numberline {2.3}Object tracking algorithms}{36}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}SORT}{36}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}DeepSORT}{37}{subsection.2.3.2}%
\contentsline {section}{\numberline {2.4}Egocentric vision datasets}{39}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}GTEA family datatsets}{39}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}EgoHands dataset}{41}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Micand32 dataset}{43}{subsection.2.4.3}%
\contentsline {chapter}{\numberline {3}Proposed Framework}{49}{chapter.3}%
\contentsline {section}{\numberline {3.1}Proposed framework: tracking by detection}{49}{section.3.1}%
\contentsline {section}{\numberline {3.2}Training stage}{51}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Training detection and segmentation models}{51}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Training deep appearance descriptor for DeepSORT}{54}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}Inference stage}{56}{section.3.3}%
\contentsline {section}{\numberline {3.4}Evaluation stage}{58}{section.3.4}%
\contentsline {chapter}{\numberline {4}Experiments}{61}{chapter.4}%
\contentsline {section}{\numberline {4.1}Evaluation criteria}{61}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Object detection metrics}{61}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Object tracking metrics}{62}{subsection.4.1.2}%
\contentsline {section}{\numberline {4.2}Experimental results}{64}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Egocentric hand detection and segmentation result}{64}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Egocentric hand tracking result}{64}{subsection.4.2.2}%
\contentsline {subsubsection}{Short-term tracking on a standard dataset: Micand32S}{66}{table.4.4}%
\contentsline {subsubsection}{Long-term tracking on a realistic dataset: Micand32E}{67}{table.4.5}%
\contentsline {section}{\numberline {4.3}Discussions}{68}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Object detection: tradeoff between accuracy and speed}{68}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}The superiority of DeepSORT over SORT}{69}{subsection.4.3.2}%
\contentsline {subsection}{\numberline {4.3.3}Impact of detection method over tracking result}{70}{subsection.4.3.3}%
\contentsline {subsection}{\numberline {4.3.4}Complexsity of 4 types of patients's actions}{71}{subsection.4.3.4}%
\contentsline {subsection}{\numberline {4.3.5}Challenging cases}{71}{subsection.4.3.5}%
\contentsline {chapter}{\numberline {5}Conclusion}{75}{chapter.5}%
\contentsline {section}{\numberline {5.1}Conclusion}{75}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Accomplishment}{75}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Drawback}{76}{subsection.5.1.2}%
\contentsline {section}{\numberline {5.2}Future works}{76}{section.5.2}%
\contentsline {chapter}{\numberline {A}Tables}{79}{appendix.A}%
\contentsline {chapter}{\numberline {B}Figures}{83}{appendix.B}%
\contentsline {section}{\numberline {B.1}Short-term tracking results on Micand32S}{83}{section.B.1}%
\contentsline {section}{\numberline {B.2}Long-term tracking results on Micand32E}{83}{section.B.2}%
\contentsline {section}{\numberline {B.3}Other}{83}{section.B.3}%
